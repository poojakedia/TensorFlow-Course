{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojakedia/TensorFlow-Course/blob/master/Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# English to Python 2\n",
        "\n",
        "In this notebook, we build on the English to Python model by adding Attention."
      ],
      "metadata": {
        "id": "sz4jtwxfdsRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention\n",
        "\n",
        "As we saw, our encoder-to-decoder model doesn't really perform all that well. Our loss is very high! Let's see if we can lower this.\n",
        "\n",
        "Let's say someone asks you to translate a sentence from English to another language. Ask yourself, is the translation a word-by-word translation of the English sentence? Furthermore, do you translate the sentence based on every word, or based on a couple words? For example, to translate the sentence \"The dog jumped over the moon\", do you need to focus on every word?\n",
        "\n",
        "It turns out, when we perform translation tasks, it isn't entirely important to us what every single word is. What matters is the context is the same for both sentences. Furthermore, one of the biggest issues with the encoder-to-decoder model is that we are trying to squish all context into one vector. As a result, the model struggles to understand what we are inputting.\n",
        "\n",
        "Hence, we can improve this model by adding Attention.\n",
        "\n",
        "Attention stems from the state-of-the-art paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762). This paper is arguably the most important paper right now so I highly recommend reading/skimming through it. We will talk about the Transformer Model and Self-Attention next week.\n",
        "\n",
        "Visually, here is what attention looks like:\n",
        "\n",
        "![img](https://jalammar.github.io/images/t/transformer_self-attention_visualization.png)\n",
        "\n",
        "In the visual, you can see that when the model looks to identify what \"it\" refers to, the model focuses its \"attention\" onto the input words with different \"strengths of attention\" on each word. For example, you can see the word \"animal\" highlighted in dark orange whereas the word \"tire\" is highlighted in a very light shade of orange.\n",
        "\n",
        "### How Does Attention Work?\n",
        "Earlier, I said that each word has a different strength of attention. The way this works can be illustrated in the below image:\n",
        "\n",
        "![img alt](https://miro.medium.com/v2/resize:fit:1040/1*WfgLRzrwiGacqPaJqGYgag.png)\n",
        "\n",
        "Recall that in the encoder model, we not only got the final hidden state output (the context vector, which we passed to the decoder as the initial hidden state), but we also got an output at each time step. Each output represents a encoded vector of the word at the time step. Instead of just passing the context vector to the decoder, we can also have the decoder take in the encoded vectors. For each encoded vector, we can concate (or add/average) it with the last hidden state in the decoder, s_i-1. Then, we pass this vector into an artificial neural network (ANN) with 1 output. This output would be e_ij, as shown in the above image. Now, at this point, each timestep would have a score e_ij, where i = time step of encoder and j = time step of decoder. We can then apply a softmax on this vector of scores to get a score between 0 and 1 for each timestep i. We can call the new score a_ij, as shown in the above image. Now each encoded vector i has a corresponding attention weight a_ij. We can now combine these weights and vectors into a single context vector c_i by taking a weighted summation as shown in the image above. At this point, we now have our context vector which we can input into the model. However, we also need the model to take in the the last output as input so that the model can understand what it generated last. You can average the values of both vectors (feel free to experiment with this!)"
      ],
      "metadata": {
        "id": "IQmg2V4xAzDa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnZXAblMVaJQ"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchtext\n",
        "from torchtext.data import get_tokenizer\n",
        "import tokenize\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Setting the device for model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieving the data\n",
        "!wget \"https://drive.google.com/u/0/uc?id=1rHb0FQ5z5ZpaY2HpyFGY6CeyDG0kTLoO&export=download\" -O english_python_data.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA7POBRLVkQr",
        "outputId": "c4c1b41c-e5af-495b-8343-70e658808f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-13 00:16:37--  https://drive.google.com/u/0/uc?id=1rHb0FQ5z5ZpaY2HpyFGY6CeyDG0kTLoO&export=download\n",
            "Resolving drive.google.com (drive.google.com)... 108.177.112.101, 108.177.112.100, 108.177.112.102, ...\n",
            "Connecting to drive.google.com (drive.google.com)|108.177.112.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://drive.google.com/uc?id=1rHb0FQ5z5ZpaY2HpyFGY6CeyDG0kTLoO&export=download [following]\n",
            "--2023-11-13 00:16:37--  https://drive.google.com/uc?id=1rHb0FQ5z5ZpaY2HpyFGY6CeyDG0kTLoO&export=download\n",
            "Reusing existing connection to drive.google.com:443.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-14-3o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/k3pb3bul09682g2prsmb51kbo2ng9tcf/1699834575000/02008525212197398114/*/1rHb0FQ5z5ZpaY2HpyFGY6CeyDG0kTLoO?e=download&uuid=c5b348d0-3a5c-4faa-aed4-e2052241c345 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-11-13 00:16:38--  https://doc-14-3o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/k3pb3bul09682g2prsmb51kbo2ng9tcf/1699834575000/02008525212197398114/*/1rHb0FQ5z5ZpaY2HpyFGY6CeyDG0kTLoO?e=download&uuid=c5b348d0-3a5c-4faa-aed4-e2052241c345\n",
            "Resolving doc-14-3o-docs.googleusercontent.com (doc-14-3o-docs.googleusercontent.com)... 74.125.132.132, 2607:f8b0:4001:c00::84\n",
            "Connecting to doc-14-3o-docs.googleusercontent.com (doc-14-3o-docs.googleusercontent.com)|74.125.132.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1122316 (1.1M) [text/plain]\n",
            "Saving to: ‘english_python_data.txt’\n",
            "\n",
            "english_python_data 100%[===================>]   1.07M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-11-13 00:16:38 (59.7 MB/s) - ‘english_python_data.txt’ saved [1122316/1122316]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Examining the dataset\n",
        "with open('english_python_data.txt',\"r\") as data_file:\n",
        "  print(data_file.readlines()[:5]) # Printing out the first 5 lines of the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX5biTq-Wfvx",
        "outputId": "2da6e603-7e5f-4396-84e3-d46e9eafdb14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['# write a python program to add two numbers \\n', 'num1 = 1.5\\n', 'num2 = 6.3\\n', 'sum = num1 + num2\\n', \"print(f'Sum: {sum}')\\n\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a dataset\n",
        "with open('english_python_data.txt',\"r\") as data_file:\n",
        "  data_lines = data_file.readlines()\n",
        "  dps = [] # List of dictionaries\n",
        "  dp = None # The current problem and solution\n",
        "  for line in data_lines:\n",
        "    if line[0] == \"#\":\n",
        "      if dp:\n",
        "        dp['solution'] = ''.join(dp['solution'])\n",
        "        dps.append(dp)\n",
        "      dp = {\"question\": None, \"solution\": []}\n",
        "      dp['question'] = line[1:]\n",
        "    else:\n",
        "      dp[\"solution\"].append(line)\n",
        "\n",
        "# converting the data to a table for easier viewing\n",
        "dataset = pd.DataFrame(dps)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZSoeDUchW8lU",
        "outputId": "a6315c58-93af-4a9a-877f-7c0635249553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               question  \\\n",
              "0          write a python program to add two numbers \\n   \n",
              "1      write a python function to add two user provi...   \n",
              "2      write a program to find and print the largest...   \n",
              "3      write a program to find and print the smalles...   \n",
              "4      Write a python function to merge two given li...   \n",
              "...                                                 ...   \n",
              "4952   Write a program to print bit wise AND of two ...   \n",
              "4953   Write a program to print bit wise OR of two n...   \n",
              "4954   Write a program to print bit wise XOR of two ...   \n",
              "4955   Write a program to calculate Binary Ones Comp...   \n",
              "4956    write a program to Binary Left Shift a number\\n   \n",
              "\n",
              "                                               solution  \n",
              "0     num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...  \n",
              "1     def add_two_numbers(num1, num2):\\n    sum = nu...  \n",
              "2     \\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >=...  \n",
              "3     num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...  \n",
              "4     def merge_lists(l1, l2):\\n    return l1 + l2\\n...  \n",
              "...                                                 ...  \n",
              "4952  a = 60            # 60 = 0011 1100\\nb = 13    ...  \n",
              "4953  a = 60\\nb = 13\\n\\nc = a | b\\nprint(\"OR\", c)\\n\\n\\n  \n",
              "4954  a = 60\\nb = 13\\n\\nc = a ^ b\\nprint(\"XOR\", c)\\n...  \n",
              "4955  a = 60\\n\\nc = ~a\\nprint(\"Binary Ones Complemen...  \n",
              "4956    c = a << 2\\nprint(\"Binary Left Shift\", c)\\n\\n\\n  \n",
              "\n",
              "[4957 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-483d577c-3fc3-4127-bda8-2544a568a406\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>solution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python program to add two numbers \\n</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add two user provi...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n    sum = nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a program to find and print the largest...</td>\n",
              "      <td>\\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;=...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the smalles...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Write a python function to merge two given li...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n    return l1 + l2\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4952</th>\n",
              "      <td>Write a program to print bit wise AND of two ...</td>\n",
              "      <td>a = 60            # 60 = 0011 1100\\nb = 13    ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4953</th>\n",
              "      <td>Write a program to print bit wise OR of two n...</td>\n",
              "      <td>a = 60\\nb = 13\\n\\nc = a | b\\nprint(\"OR\", c)\\n\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4954</th>\n",
              "      <td>Write a program to print bit wise XOR of two ...</td>\n",
              "      <td>a = 60\\nb = 13\\n\\nc = a ^ b\\nprint(\"XOR\", c)\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4955</th>\n",
              "      <td>Write a program to calculate Binary Ones Comp...</td>\n",
              "      <td>a = 60\\n\\nc = ~a\\nprint(\"Binary Ones Complemen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4956</th>\n",
              "      <td>write a program to Binary Left Shift a number\\n</td>\n",
              "      <td>c = a &lt;&lt; 2\\nprint(\"Binary Left Shift\", c)\\n\\n\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4957 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-483d577c-3fc3-4127-bda8-2544a568a406')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-483d577c-3fc3-4127-bda8-2544a568a406 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-483d577c-3fc3-4127-bda8-2544a568a406');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1be35906-5d4f-405a-ba33-142f6c467372\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1be35906-5d4f-405a-ba33-142f6c467372')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1be35906-5d4f-405a-ba33-142f6c467372 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at the first question and the corresponding solution\n",
        "print(dataset.loc[0,'question'])\n",
        "print(dataset.loc[0,'solution'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmLYEtxcZY5i",
        "outputId": "e913808c-1baf-4191-b3e3-b3596dbcd33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " write a python program to add two numbers \n",
            "\n",
            "num1 = 1.5\n",
            "num2 = 6.3\n",
            "sum = num1 + num2\n",
            "print(f'Sum: {sum}')\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a class that holds the vocabulary mappings for each\n",
        "# \"Language\" (English and Python in our case)\n",
        "\n",
        "# Setting the SOS and EOS tokens\n",
        "SOS_token = 1\n",
        "EOS_token = 2\n",
        "\n",
        "class Language:\n",
        "  def __init__(self,name):\n",
        "    self.name = name\n",
        "    self.word2index = {'SOS':1,'EOS':2}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {1:'SOS',2:'EOS'}\n",
        "    self.n_words = 3\n",
        "\n",
        "  # method to add sentences\n",
        "  def addSentence(self, sentence):\n",
        "    for word in sentence:\n",
        "      self.addWord(word)\n",
        "\n",
        "  # Method to add a word\n",
        "  def addWord(self,word):\n",
        "    if word not in self.word2index.keys():\n",
        "      self.word2index[word] = self.n_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.n_words] = word\n",
        "      self.n_words += 1\n",
        "    else:\n",
        "      self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "CxknNB9iZb16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the Python Code\n",
        "# For this one, I just need to tokenize the Python code\n",
        "indicies_to_ignore = [] # indicies that have broken Python code\n",
        "tokenized_python = []\n",
        "for i in range(dataset.shape[0]):\n",
        "  try:\n",
        "    solution = dataset.loc[i,'solution'].strip(\"\\n \") # Stripping \\n\n",
        "    tokenized_code = [token.string for token in list(tokenize.generate_tokens(io.StringIO(solution).readline)) if token.string] # also removing empty characters\n",
        "    tokenized_python.append(tokenized_code)\n",
        "  except:\n",
        "    indicies_to_ignore.append(i)\n",
        "print(f'Total Acceptable Examples: {len(tokenized_python)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfvrKzJgbXdm",
        "outputId": "940a4843-b223-4ed4-e6d0-b18261d5e03a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Acceptable Examples: 4928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the indicies that were in the indicies_to_ignore list.\n",
        "# Python code was written properly for me to utilize that example.\n",
        "dataset_copy = dataset.copy()\n",
        "dataset_copy.drop(indicies_to_ignore,inplace=True)\n",
        "dataset_copy.reset_index(drop=True, inplace=True)\n",
        "dataset_copy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9m_TXrj-bazi",
        "outputId": "d22c44c2-2113-448b-fc37-eab3c8aac185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               question  \\\n",
              "0          write a python program to add two numbers \\n   \n",
              "1      write a python function to add two user provi...   \n",
              "2      write a program to find and print the largest...   \n",
              "3      write a program to find and print the smalles...   \n",
              "4      Write a python function to merge two given li...   \n",
              "...                                                 ...   \n",
              "4923   Write a program to print bit wise AND of two ...   \n",
              "4924   Write a program to print bit wise OR of two n...   \n",
              "4925   Write a program to print bit wise XOR of two ...   \n",
              "4926   Write a program to calculate Binary Ones Comp...   \n",
              "4927    write a program to Binary Left Shift a number\\n   \n",
              "\n",
              "                                               solution  \n",
              "0     num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...  \n",
              "1     def add_two_numbers(num1, num2):\\n    sum = nu...  \n",
              "2     \\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >=...  \n",
              "3     num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...  \n",
              "4     def merge_lists(l1, l2):\\n    return l1 + l2\\n...  \n",
              "...                                                 ...  \n",
              "4923  a = 60            # 60 = 0011 1100\\nb = 13    ...  \n",
              "4924  a = 60\\nb = 13\\n\\nc = a | b\\nprint(\"OR\", c)\\n\\n\\n  \n",
              "4925  a = 60\\nb = 13\\n\\nc = a ^ b\\nprint(\"XOR\", c)\\n...  \n",
              "4926  a = 60\\n\\nc = ~a\\nprint(\"Binary Ones Complemen...  \n",
              "4927    c = a << 2\\nprint(\"Binary Left Shift\", c)\\n\\n\\n  \n",
              "\n",
              "[4928 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-753781f3-eb65-420d-89c3-d968195a6c1b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>solution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python program to add two numbers \\n</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add two user provi...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n    sum = nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a program to find and print the largest...</td>\n",
              "      <td>\\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;=...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the smalles...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Write a python function to merge two given li...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n    return l1 + l2\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4923</th>\n",
              "      <td>Write a program to print bit wise AND of two ...</td>\n",
              "      <td>a = 60            # 60 = 0011 1100\\nb = 13    ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4924</th>\n",
              "      <td>Write a program to print bit wise OR of two n...</td>\n",
              "      <td>a = 60\\nb = 13\\n\\nc = a | b\\nprint(\"OR\", c)\\n\\n\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4925</th>\n",
              "      <td>Write a program to print bit wise XOR of two ...</td>\n",
              "      <td>a = 60\\nb = 13\\n\\nc = a ^ b\\nprint(\"XOR\", c)\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4926</th>\n",
              "      <td>Write a program to calculate Binary Ones Comp...</td>\n",
              "      <td>a = 60\\n\\nc = ~a\\nprint(\"Binary Ones Complemen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4927</th>\n",
              "      <td>write a program to Binary Left Shift a number\\n</td>\n",
              "      <td>c = a &lt;&lt; 2\\nprint(\"Binary Left Shift\", c)\\n\\n\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4928 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-753781f3-eb65-420d-89c3-d968195a6c1b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-753781f3-eb65-420d-89c3-d968195a6c1b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-753781f3-eb65-420d-89c3-d968195a6c1b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6cf18bbc-4678-4bfe-a983-543bd01a37a7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6cf18bbc-4678-4bfe-a983-543bd01a37a7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6cf18bbc-4678-4bfe-a983-543bd01a37a7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning the English texts\n",
        "cleaned_english = []\n",
        "url_pattern = re.compile(r\"https?://\\S+\")\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "for i in range(dataset_copy.shape[0]):\n",
        "  sentence = dataset_copy.loc[i,'question']\n",
        "  sentence = sentence.lower() # lowercasing everything\n",
        "  sentence = sentence.strip(\"\\n\") # removing \\n\n",
        "  sentence = url_pattern.sub('',sentence) # Replacing any urls\n",
        "  sentence = re.sub(r\"([.!?])\",\"\",sentence) # removing any punctuation\n",
        "  sentence = re.sub(r'^\\d+ ',\"\",sentence)\n",
        "  sentence = tokenizer(sentence) # tokenizing\n",
        "  sentence = [stemmer.stem(word) for word in sentence] # Stemming\n",
        "  cleaned_english.append(sentence)\n",
        "\n",
        "print(f'Number of Sentences: {len(cleaned_english)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQduSwdYdO9J",
        "outputId": "f63589bf-dd76-4bbe-8563-2190ff61f0f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Sentences: 4928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zipping everything together to get a complete dataset\n",
        "prepared_data = list(zip(cleaned_english,tokenized_python))"
      ],
      "metadata": {
        "id": "BNrBhOgMgTw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the 2 vocabularies\n",
        "english_lang = Language('english')\n",
        "python_lang = Language('python')\n",
        "\n",
        "# Populating the vocabularies\n",
        "for (english, python) in prepared_data:\n",
        "  english_lang.addSentence(english)\n",
        "  python_lang.addSentence(python)"
      ],
      "metadata": {
        "id": "rHxPDKuOgVyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the number of words in each vocabulary\n",
        "print(f'Number of words in the English Vocabulary: {english_lang.n_words}')\n",
        "print(f'Number of words in the Python Vocabulary: {python_lang.n_words}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ldRMSW7gbJQ",
        "outputId": "a3a34ac7-5887-4e99-e0bb-c578d358763e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in the English Vocabulary: 1987\n",
            "Number of words in the Python Vocabulary: 6873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the maximum length for both sequences\n",
        "max_length_eng = 0\n",
        "max_length_python = 0\n",
        "avg_eng_length = 0\n",
        "avg_python_length = 0\n",
        "number_of_pairs = 0\n",
        "\n",
        "for (english,python) in prepared_data:\n",
        "  if len(english) > max_length_eng:\n",
        "    max_length_eng = len(english)\n",
        "\n",
        "  if len(python) > max_length_python:\n",
        "    max_length_python = len(python)\n",
        "\n",
        "  number_of_pairs += 1\n",
        "  avg_eng_length += len(english)\n",
        "  avg_python_length += len(python)\n",
        "\n",
        "# Printing out the maximum lengths\n",
        "print(f'Maximum Length of an English Sentence: {max_length_eng}')\n",
        "print(f'Maximum Length of Python code: {max_length_python}')\n",
        "\n",
        "# Printing out the average lengths\n",
        "print(f'Average Length of an English Sentence: {avg_eng_length / number_of_pairs}')\n",
        "print(f'Average Length of Python code: {avg_python_length / number_of_pairs}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_XnymwigmjX",
        "outputId": "c1a197e4-656b-4bf3-b89b-b74e72131558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum Length of an English Sentence: 71\n",
            "Maximum Length of Python code: 750\n",
            "Average Length of an English Sentence: 12.633928571428571\n",
            "Average Length of Python code: 44.77617694805195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the dataset\n",
        "final_prepared_data = []\n",
        "for (english,python) in prepared_data:\n",
        "  english_sentence = ['SOS']\n",
        "  english_sentence.extend(english)\n",
        "  english_sentence.append('EOS')\n",
        "\n",
        "  python_sentence = ['SOS']\n",
        "  python_sentence.extend(python)\n",
        "  python_sentence.append('EOS')\n",
        "\n",
        "  # Tokenizing the english sentences\n",
        "  tokenized_english = []\n",
        "  for word in english_sentence:\n",
        "    tokenized_english.append(english_lang.word2index[word])\n",
        "\n",
        "  # Tokenizing the python sentences\n",
        "  tokenized_python = []\n",
        "  for word in python_sentence:\n",
        "    tokenized_python.append(python_lang.word2index[word])\n",
        "\n",
        "  # Getting the padding needed\n",
        "  \"\"\"\n",
        "\n",
        "  You might want to play around with the max length!\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  padding_needed_eng = 21 - len(tokenized_english)\n",
        "  padding_needed_python = 51 - len(tokenized_python)\n",
        "\n",
        "  # Checking if I need to trim\n",
        "  if padding_needed_eng <= 0:\n",
        "    tokenized_english = tokenized_english[:20]\n",
        "    tokenized_english.append(EOS_token)\n",
        "    tokenized_english = torch.from_numpy(np.array(tokenized_english))\n",
        "  else:\n",
        "    tokenized_english = nn.functional.pad(torch.from_numpy(np.array(tokenized_english)),(0,padding_needed_eng))\n",
        "\n",
        "  # Checking if I need to trim for Python\n",
        "  if padding_needed_python <= 0:\n",
        "    tokenized_python = tokenized_python[:50]\n",
        "    tokenized_python.append(EOS_token)\n",
        "    tokenized_python = torch.from_numpy(np.array(tokenized_python))\n",
        "  else:\n",
        "    tokenized_python = nn.functional.pad(torch.from_numpy(np.array(tokenized_python)),(0,padding_needed_python))\n",
        "\n",
        "  final_prepared_data.append((tokenized_english.numpy(),tokenized_python.numpy()))"
      ],
      "metadata": {
        "id": "l3iAPgTVi0Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into training, testing, and validation\n",
        "training, testing = train_test_split(final_prepared_data,test_size=0.2,random_state=42,shuffle=True)\n",
        "\n",
        "# Splitting the data into inputs and outputs\n",
        "inputs_train = torch.Tensor([pair[0] for pair in training])\n",
        "outputs_train = torch.Tensor([pair[1] for pair in training])\n",
        "inputs_test = torch.Tensor([pair[0] for pair in testing])\n",
        "outputs_test = torch.Tensor([pair[1] for pair in testing])\n",
        "\n",
        "# Creating the Tensor Datasets\n",
        "training_dataset = TensorDataset(inputs_train,outputs_train)\n",
        "testing_dataset = TensorDataset(inputs_test,outputs_test)\n",
        "\n",
        "# Building the data loaders\n",
        "training_dataloader = DataLoader(training_dataset,batch_size=32,shuffle=True)\n",
        "testing_dataloader = DataLoader(testing_dataset,batch_size=32,shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7lIZ65LkVPR",
        "outputId": "c5bc657e-6075-43a8-d6cf-22a5f4f03164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-4ed79e77974d>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  inputs_train = torch.Tensor([pair[0] for pair in training])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Building the Encoder\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self,input_size=english_lang.n_words,hidden_size=30,dropout_p=0.2):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    This is the encoder, this is where you will build a custom encoder!\n",
        "\n",
        "    \"\"\"\n",
        "    self.embedding = nn.Embedding(input_size,hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size,hidden_size,batch_first=True)\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    embedded = self.dropout(self.embedding(inputs))\n",
        "    outputs, hiddens = self.gru(embedded)\n",
        "    return outputs, hiddens"
      ],
      "metadata": {
        "id": "rb5aEJJ5l3dY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Decoder\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self,hidden_size=30,output_size=python_lang.n_words):\n",
        "    super().__init__()\n",
        "    \"\"\"\n",
        "\n",
        "    This is the decoder, this is where you build a custom decoder!\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    self.embedding = nn.Embedding(output_size,hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size,hidden_size,batch_first=True)\n",
        "    self.out = nn.Linear(hidden_size,output_size)\n",
        "\n",
        "    # ANN for attention\n",
        "    self.attent1 = nn.Linear(hidden_size * 2,50)\n",
        "    self.attention_out = nn.Linear(50,1)\n",
        "\n",
        "  def forward(self,encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "    batch_size = encoder_outputs.size(0)\n",
        "    decoder_input = torch.empty(batch_size,1,dtype=torch.long,device=device).fill_(SOS_token)\n",
        "    decoder_hidden = encoder_hidden.squeeze(dim=0)\n",
        "    decoder_hidden = decoder_hidden.unsqueeze(dim=1)\n",
        "    decoder_outputs = []\n",
        "\n",
        "    for i in range(51):\n",
        "      # Calculating the attention weights\n",
        "      concatenated_vector = torch.cat([decoder_hidden.expand(-1,21,-1),encoder_outputs],dim=2)\n",
        "      attention_weights = nn.functional.softmax(self.attention_out(nn.functional.tanh(self.attent1(concatenated_vector))),dim=1)\n",
        "      attention_weights = torch.reshape(attention_weights,(-1,1,21))\n",
        "      context_vector = torch.bmm(attention_weights,encoder_outputs)\n",
        "\n",
        "      # Sending the decoder input through the embedding\n",
        "      decoder_input = self.embedding(decoder_input)\n",
        "      decoder_input = decoder_input + context_vector\n",
        "      decoder_output, decoder_hidden = self.forward_step(decoder_input,decoder_hidden)\n",
        "      decoder_outputs.append(decoder_output)\n",
        "\n",
        "      if target_tensor is not None:\n",
        "        decoder_input = target_tensor[:,i].unsqueeze(1)\n",
        "      else:\n",
        "        # Making predictions\n",
        "        _, topi = nn.functional.softmax(decoder_output,dim=1).topk(1)\n",
        "        decoder_input = topi.squeeze(-1).detach()\n",
        "\n",
        "    decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "    return decoder_outputs, decoder_hidden\n",
        "\n",
        "  def forward_step(self,inputs,hidden):\n",
        "    batch_size = hidden.size(0)\n",
        "    output, hidden = self.gru(inputs,torch.reshape(hidden,(1,batch_size,-1)))\n",
        "    output = self.out(output)\n",
        "    return output, torch.reshape(hidden,(batch_size,1,-1))"
      ],
      "metadata": {
        "id": "0Irt-HBFoNj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the model\n",
        "\"\"\"\n",
        "\n",
        "This is where we define the model,\n",
        "you may also need to tune this part\n",
        "as well!\n",
        "\n",
        "\"\"\"\n",
        "encoder = Encoder(hidden_size=200)\n",
        "decoder = Decoder(hidden_size=200)\n",
        "encoder.to(device)\n",
        "decoder.to(device)\n",
        "\n",
        "# Defining model metrics\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "You may need to play with the optimizer and the learning rate.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "encoder_optim = optim.Adam(encoder.parameters(),lr=0.001)\n",
        "decoder_optim = optim.Adam(decoder.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "p0O4oadWpmwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function for training on each epoch\n",
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer,loss_fn, dataset):\n",
        "  # Setting the model to training model\n",
        "  encoder.train()\n",
        "  decoder.train()\n",
        "\n",
        "  total_loss = 0\n",
        "  for X, y in dataloader:\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    encoder_outputs, encoder_hidden = encoder(X.int())\n",
        "    decoder_outputs, _ = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "    # One-hot-encoding y\n",
        "    y = nn.functional.one_hot(y.to(torch.int64),num_classes=python_lang.n_words)\n",
        "\n",
        "    loss = loss_fn(decoder_outputs.float(),y.float())\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    total_loss += loss\n",
        "  return total_loss / len(dataset)"
      ],
      "metadata": {
        "id": "jKEwbeejrMoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "training_losses = []\n",
        "epochs = 150 # You may need to change the number of epochs!!!\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  loss = train_epoch(training_dataloader,encoder,decoder,encoder_optim,decoder_optim,loss_fn,training_dataset)\n",
        "  training_losses.append(loss.item())\n",
        "  print(f'Epoch {epoch}')\n",
        "  print(loss.item())\n",
        "  print()"
      ],
      "metadata": {
        "id": "iRPcA7y9sJ8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea34cd48-b244-4de4-cf60-b0aebdd98fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "184.5426788330078\n",
            "\n",
            "Epoch 1\n",
            "178.2742156982422\n",
            "\n",
            "Epoch 2\n",
            "174.96620178222656\n",
            "\n",
            "Epoch 3\n",
            "172.2029571533203\n",
            "\n",
            "Epoch 4\n",
            "169.81622314453125\n",
            "\n",
            "Epoch 5\n",
            "167.8396453857422\n",
            "\n",
            "Epoch 6\n",
            "165.69589233398438\n",
            "\n",
            "Epoch 7\n",
            "164.05767822265625\n",
            "\n",
            "Epoch 8\n",
            "162.61427307128906\n",
            "\n",
            "Epoch 9\n",
            "160.84939575195312\n",
            "\n",
            "Epoch 10\n",
            "159.71839904785156\n",
            "\n",
            "Epoch 11\n",
            "158.4272918701172\n",
            "\n",
            "Epoch 12\n",
            "157.3994140625\n",
            "\n",
            "Epoch 13\n",
            "156.3924560546875\n",
            "\n",
            "Epoch 14\n",
            "155.49966430664062\n",
            "\n",
            "Epoch 15\n",
            "154.81744384765625\n",
            "\n",
            "Epoch 16\n",
            "153.95559692382812\n",
            "\n",
            "Epoch 17\n",
            "153.12265014648438\n",
            "\n",
            "Epoch 18\n",
            "152.0305633544922\n",
            "\n",
            "Epoch 19\n",
            "151.28334045410156\n",
            "\n",
            "Epoch 20\n",
            "150.6188507080078\n",
            "\n",
            "Epoch 21\n",
            "149.94309997558594\n",
            "\n",
            "Epoch 22\n",
            "149.2940673828125\n",
            "\n",
            "Epoch 23\n",
            "148.4418487548828\n",
            "\n",
            "Epoch 24\n",
            "147.79331970214844\n",
            "\n",
            "Epoch 25\n",
            "147.15420532226562\n",
            "\n",
            "Epoch 26\n",
            "146.39035034179688\n",
            "\n",
            "Epoch 27\n",
            "146.0203094482422\n",
            "\n",
            "Epoch 28\n",
            "145.43524169921875\n",
            "\n",
            "Epoch 29\n",
            "144.9259490966797\n",
            "\n",
            "Epoch 30\n",
            "144.90322875976562\n",
            "\n",
            "Epoch 31\n",
            "144.33078002929688\n",
            "\n",
            "Epoch 32\n",
            "143.41123962402344\n",
            "\n",
            "Epoch 33\n",
            "142.6684112548828\n",
            "\n",
            "Epoch 34\n",
            "142.04063415527344\n",
            "\n",
            "Epoch 35\n",
            "141.8147735595703\n",
            "\n",
            "Epoch 36\n",
            "141.17149353027344\n",
            "\n",
            "Epoch 37\n",
            "141.03811645507812\n",
            "\n",
            "Epoch 38\n",
            "141.07398986816406\n",
            "\n",
            "Epoch 39\n",
            "140.1741485595703\n",
            "\n",
            "Epoch 40\n",
            "139.76991271972656\n",
            "\n",
            "Epoch 41\n",
            "138.83692932128906\n",
            "\n",
            "Epoch 42\n",
            "138.12750244140625\n",
            "\n",
            "Epoch 43\n",
            "137.97085571289062\n",
            "\n",
            "Epoch 44\n",
            "137.52406311035156\n",
            "\n",
            "Epoch 45\n",
            "137.11924743652344\n",
            "\n",
            "Epoch 46\n",
            "137.0558624267578\n",
            "\n",
            "Epoch 47\n",
            "136.60601806640625\n",
            "\n",
            "Epoch 48\n",
            "137.84507751464844\n",
            "\n",
            "Epoch 49\n",
            "136.2654571533203\n",
            "\n",
            "Epoch 50\n",
            "135.44386291503906\n",
            "\n",
            "Epoch 51\n",
            "140.7340545654297\n",
            "\n",
            "Epoch 52\n",
            "139.46583557128906\n",
            "\n",
            "Epoch 53\n",
            "140.96287536621094\n",
            "\n",
            "Epoch 54\n",
            "138.40084838867188\n",
            "\n",
            "Epoch 55\n",
            "136.23178100585938\n",
            "\n",
            "Epoch 56\n",
            "135.23878479003906\n",
            "\n",
            "Epoch 57\n",
            "134.6620330810547\n",
            "\n",
            "Epoch 58\n",
            "134.02928161621094\n",
            "\n",
            "Epoch 59\n",
            "133.7527618408203\n",
            "\n",
            "Epoch 60\n",
            "133.46755981445312\n",
            "\n",
            "Epoch 61\n",
            "132.6910858154297\n",
            "\n",
            "Epoch 62\n",
            "132.11700439453125\n",
            "\n",
            "Epoch 63\n",
            "132.19564819335938\n",
            "\n",
            "Epoch 64\n",
            "131.80079650878906\n",
            "\n",
            "Epoch 65\n",
            "131.38739013671875\n",
            "\n",
            "Epoch 66\n",
            "131.67750549316406\n",
            "\n",
            "Epoch 67\n",
            "131.4717254638672\n",
            "\n",
            "Epoch 68\n",
            "130.85113525390625\n",
            "\n",
            "Epoch 69\n",
            "130.98377990722656\n",
            "\n",
            "Epoch 70\n",
            "130.46466064453125\n",
            "\n",
            "Epoch 71\n",
            "130.0680694580078\n",
            "\n",
            "Epoch 72\n",
            "129.47789001464844\n",
            "\n",
            "Epoch 73\n",
            "129.14874267578125\n",
            "\n",
            "Epoch 74\n",
            "129.33824157714844\n",
            "\n",
            "Epoch 75\n",
            "129.0381317138672\n",
            "\n",
            "Epoch 76\n",
            "129.75485229492188\n",
            "\n",
            "Epoch 77\n",
            "129.48150634765625\n",
            "\n",
            "Epoch 78\n",
            "128.86990356445312\n",
            "\n",
            "Epoch 79\n",
            "128.12818908691406\n",
            "\n",
            "Epoch 80\n",
            "128.64524841308594\n",
            "\n",
            "Epoch 81\n",
            "128.02923583984375\n",
            "\n",
            "Epoch 82\n",
            "127.24002075195312\n",
            "\n",
            "Epoch 83\n",
            "126.89387512207031\n",
            "\n",
            "Epoch 84\n",
            "126.47572326660156\n",
            "\n",
            "Epoch 85\n",
            "126.64370727539062\n",
            "\n",
            "Epoch 86\n",
            "126.67597961425781\n",
            "\n",
            "Epoch 87\n",
            "125.9902114868164\n",
            "\n",
            "Epoch 88\n",
            "125.77153778076172\n",
            "\n",
            "Epoch 89\n",
            "130.608642578125\n",
            "\n",
            "Epoch 90\n",
            "127.86400604248047\n",
            "\n",
            "Epoch 91\n",
            "128.46788024902344\n",
            "\n",
            "Epoch 92\n",
            "134.59695434570312\n",
            "\n",
            "Epoch 93\n",
            "134.80995178222656\n",
            "\n",
            "Epoch 94\n",
            "130.46124267578125\n",
            "\n",
            "Epoch 95\n",
            "128.83290100097656\n",
            "\n",
            "Epoch 96\n",
            "127.71757507324219\n",
            "\n",
            "Epoch 97\n",
            "126.60181427001953\n",
            "\n",
            "Epoch 98\n",
            "126.76321411132812\n",
            "\n",
            "Epoch 99\n",
            "129.90809631347656\n",
            "\n",
            "Epoch 100\n",
            "128.01080322265625\n",
            "\n",
            "Epoch 101\n",
            "125.864990234375\n",
            "\n",
            "Epoch 102\n",
            "124.84021759033203\n",
            "\n",
            "Epoch 103\n",
            "124.35887145996094\n",
            "\n",
            "Epoch 104\n",
            "124.23007202148438\n",
            "\n",
            "Epoch 105\n",
            "123.99535369873047\n",
            "\n",
            "Epoch 106\n",
            "123.88742065429688\n",
            "\n",
            "Epoch 107\n",
            "123.48159790039062\n",
            "\n",
            "Epoch 108\n",
            "123.1322021484375\n",
            "\n",
            "Epoch 109\n",
            "122.67627716064453\n",
            "\n",
            "Epoch 110\n",
            "123.10833740234375\n",
            "\n",
            "Epoch 111\n",
            "123.05050659179688\n",
            "\n",
            "Epoch 112\n",
            "123.52621459960938\n",
            "\n",
            "Epoch 113\n",
            "122.70558166503906\n",
            "\n",
            "Epoch 114\n",
            "122.69645690917969\n",
            "\n",
            "Epoch 115\n",
            "123.63842010498047\n",
            "\n",
            "Epoch 116\n",
            "122.85967254638672\n",
            "\n",
            "Epoch 117\n",
            "122.39444732666016\n",
            "\n",
            "Epoch 118\n",
            "122.57352447509766\n",
            "\n",
            "Epoch 119\n",
            "122.90455627441406\n",
            "\n",
            "Epoch 120\n",
            "124.29400634765625\n",
            "\n",
            "Epoch 121\n",
            "121.77281951904297\n",
            "\n",
            "Epoch 122\n",
            "123.07317352294922\n",
            "\n",
            "Epoch 123\n",
            "127.78136444091797\n",
            "\n",
            "Epoch 124\n",
            "124.5911636352539\n",
            "\n",
            "Epoch 125\n",
            "124.39921569824219\n",
            "\n",
            "Epoch 126\n",
            "122.52794647216797\n",
            "\n",
            "Epoch 127\n",
            "121.38693237304688\n",
            "\n",
            "Epoch 128\n",
            "121.42273712158203\n",
            "\n",
            "Epoch 129\n",
            "120.82063293457031\n",
            "\n",
            "Epoch 130\n",
            "121.37245178222656\n",
            "\n",
            "Epoch 131\n",
            "120.30764770507812\n",
            "\n",
            "Epoch 132\n",
            "119.82134246826172\n",
            "\n",
            "Epoch 133\n",
            "119.82075500488281\n",
            "\n",
            "Epoch 134\n",
            "121.67855072021484\n",
            "\n",
            "Epoch 135\n",
            "124.703125\n",
            "\n",
            "Epoch 136\n",
            "121.57722473144531\n",
            "\n",
            "Epoch 137\n",
            "127.96391296386719\n",
            "\n",
            "Epoch 138\n",
            "125.43666076660156\n",
            "\n",
            "Epoch 139\n",
            "122.15066528320312\n",
            "\n",
            "Epoch 140\n",
            "120.51314544677734\n",
            "\n",
            "Epoch 141\n",
            "120.14457702636719\n",
            "\n",
            "Epoch 142\n",
            "119.74391174316406\n",
            "\n",
            "Epoch 143\n",
            "121.15653991699219\n",
            "\n",
            "Epoch 144\n",
            "122.33406066894531\n",
            "\n",
            "Epoch 145\n",
            "122.6441421508789\n",
            "\n",
            "Epoch 146\n",
            "120.72174072265625\n",
            "\n",
            "Epoch 147\n",
            "119.69503021240234\n",
            "\n",
            "Epoch 148\n",
            "119.32315063476562\n",
            "\n",
            "Epoch 149\n",
            "118.88246154785156\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure that the loss is decreasing and model is training correctly\n",
        "plt.title('Training Loss vs. Epoch')\n",
        "plt.plot(training_losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8wuL0IxwsjUi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "2844da67-418e-4054-cfe5-efb7131c7277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the loss on the training set\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "total = 0\n",
        "for X, y in training_dataloader:\n",
        "  X = X.to(device)\n",
        "  y = y.to(device)\n",
        "\n",
        "  encoder_outputs, encoder_hidden = encoder(X.int())\n",
        "  decoder_outputs, _ = decoder(encoder_outputs, encoder_hidden)\n",
        "  y_encoded = nn.functional.one_hot(y.to(torch.int64),num_classes=python_lang.n_words)\n",
        "  loss = loss_fn(decoder_outputs.float(),y_encoded.float()).item()\n",
        "  total += loss\n",
        "print(total / len(training_dataset))"
      ],
      "metadata": {
        "id": "jrb_y4CgsvVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f18a7d-9d1c-4fc9-e3b4-dfcd77cdbc8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114.147477210445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the loss on the testing set\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "total = 0\n",
        "for X, y in testing_dataloader:\n",
        "  X = X.to(device)\n",
        "  y = y.to(device)\n",
        "\n",
        "  encoder_outputs, encoder_hidden = encoder(X.int())\n",
        "  decoder_outputs, _ = decoder(encoder_outputs, encoder_hidden)\n",
        "  y_encoded = nn.functional.one_hot(y.to(torch.int64),num_classes=python_lang.n_words)\n",
        "  loss = loss_fn(decoder_outputs.float(),y_encoded.float()).item()\n",
        "  total += loss\n",
        "print(total / len(testing_dataset))"
      ],
      "metadata": {
        "id": "eRxPfj-4s66d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc43288-3738-4cec-a343-de90bfa7073a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "182.0166926819219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating Python Code\n",
        "sentence = input('Input: ')\n",
        "\n",
        "# Cleaning the input\n",
        "sentence = sentence.lower() # lowercasing everything\n",
        "sentence = url_pattern.sub('',sentence) # Replacing any urls\n",
        "sentence = re.sub(r\"([.!?])\",\"\",sentence) # removing any punctuation\n",
        "sentence = tokenizer(sentence) # tokenizing\n",
        "sentence = [stemmer.stem(word) for word in sentence] # Stemming\n",
        "\n",
        "# Converting sentence into input\n",
        "prepared_sentence = ['SOS']\n",
        "prepared_sentence.extend(sentence)\n",
        "prepared_sentence.append('EOS')\n",
        "for i in range(len(prepared_sentence)):\n",
        "    prepared_sentence[i] = english_lang.word2index[prepared_sentence[i]]\n",
        "\n",
        "# Adding the padding\n",
        "padding = 21 - len(prepared_sentence)\n",
        "\n",
        "# Checking if I need to trim\n",
        "if padding <= 0:\n",
        "  prepared_sentence = prepared_sentence[:20]\n",
        "  prepared_sentence.append(EOS_token)\n",
        "  prepared_sentence = torch.from_numpy(np.array(prepared_sentence))\n",
        "else:\n",
        "  prepared_sentence = nn.functional.pad(torch.from_numpy(np.array(prepared_sentence)),(0,padding))\n",
        "\n",
        "\n",
        "# Setting the models to evaluation mode\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "# Running through the model\n",
        "encoder_outputs, encoder_hidden = encoder(torch.from_numpy(np.array(prepared_sentence)).int().to(device))\n",
        "decoder_outputs, _ = decoder(encoder_outputs.unsqueeze(0), encoder_hidden.unsqueeze(0))\n",
        "\n",
        "# Translating the decoder to actual code\n",
        "prediction = np.argmax(nn.functional.softmax(decoder_outputs.squeeze(0),dim=1).cpu().detach().numpy(),axis=1)\n",
        "prediction_converted = []\n",
        "for i in range(len(prediction)):\n",
        "  if prediction[i] != 0:\n",
        "    prediction_converted.append(python_lang.index2word[prediction[i]])\n",
        "  else:\n",
        "    prediction_converted.append('<PAD>')\n",
        "\n",
        "# Printing out the prediction\n",
        "print(' '.join(prediction_converted))"
      ],
      "metadata": {
        "id": "PdhBddw3tBoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49dd3bec-9da0-45f0-c305-89fb7b5a30ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: write a python program to add two numbers\n",
            "\"Demo of lt and eq in class\" prior_list compute_gcd 102 \"key1\" casefold casefold \"AEIOUaeiou\" casefold casefold casefold casefold casefold \"' is\" \"' is\" else 1.8 1964 \"_\" \"age\" 'The value of x after swapping: {}' \"The total terms are:\" \"The total terms are:\" \"is not an Armstrong number\" \":\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\" \"3.Multiply\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ApP_1dynxopJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}